Новосибирский авиационный технический колледж имени Б.С. Галущака Научный руководитель Т.Д. Оболенцева

В современном мире безопасность является одной из ключевых задач для государств и организаций. С развитием информационных технологий и социальных сетей увеличивается количество угроз, связанных с терроризмом.
В данной статье рассматривается разработка нейронной сети для автоматического распознавания террористических угроз в текстовых данных. Основная цель исследования — создание модели, способной эффективно классифицировать тексты на опасные и безопасные, что позволит своевременно выявлять потенциальные угрозы. С развитием интернета и социальных сетей стало проще передавать информацию, но вместе с этим выросли и риски: угрозы, связанные с терроризмом, стали распространяться быстрее. Чтобы защитить людей, нужно уметь находить опасные сообщения среди множества, казалось бы, безобидных текстов.
Для обучения модели были использованы текстовые данные из двух источников: positive.csv и negative.csv. Эти файлы содержат текстовые сообщения, которые были предварительно размечены как опасные (положительные) и безопасные (отрицательные). Данные были собраны из различных источников, включая социальные сети, новостные сайты и форумы. Использование разнообразных источников позволяет модели учитывать широкий спектр возможных угроз и улучшает её обобщающую способность.
Компьютеры не могут понимать текст так, как люди. Для них это просто набор символов. Чтобы нейросеть могла работать с текстом, его сначала нужно подготовить. Подготовка проходит в несколько шагов: очистка данных, токенизация, создание словаря, добавление паддингов.
	Очистка данных предполагает удаление пунктуации, специальных символов и приведение текста к нижнему регистру. Это позволяет уменьшить размерность данных и упростить их обработку.
	Токенизация – это процесс разбиения текста на отдельные слова (токены).
	Создание словаря заключается в том, что каждому слову присваивается уникальный числовой индекс, или числовой формат. 
		Добавление паддингов – это приведение всех слов к одинаковой длине, например путем добавления нулей в конце каждого слова. Это позволяет стандартизировать входные данные и упростить их обработку.
Данные были разделены на три части: тренировочную (80%), валидационную (10%) и тестовую (10%). Для обеспечения случайности данные были перемешаны с помощью функции shuffle из библиотеки sklearn.utils в языке программирования Python. Разделение данных на три набора позволяет обучать модель на тренировочных данных, настраивать её гиперпараметры на валидационных данных и оценивать её производительность на тестовых данных.
Для модели была выбрана архитектура LSTM (Long Short-Term Memory), которая хорошо подходит для обработки последовательных данных таких, как текст. Модель, реализованная программой, состоит из трех скрытых слоев LSTM, что позволяет эффективно учитывать контекст и зависимости между словами в тексте. Использование нескольких слоев LSTM позволяет модели захватывать более сложные зависимости и улучшает её способность для классификации и определения текста.  
В качестве активационной функции для выходного слоя была выбрана функция Sigmoid, которая преобразует выход модели в вероятность (от 0 до 1). Это позволяет интерпретировать результат как вероятность того, что текст является опасным. Сигмоидная функция активации хорошо подходит для задач бинарной классификации, так как она позволяет получить вероятностную интерпретацию выхода модели.
Переобучение модели — это ситуация, при которой модель машинного обучения слишком хорошо подстраивается под обучающие данные, включая шум и выбросы, что приводит к снижению её способности обобщать на новых, невидимых данных. Это происходит, когда модель становится слишком сложной для данных, которые она обучает, и начинает запоминать их, вместо того чтобы выявлять общие закономерности.
Метод Dropout — это техника регуляризации, используемая для предотвращения переобучения. Она заключается в случайном отключении (или "выбрасывании") определённого процента нейронов в слоях нейронной сети во время каждой итерации обучения. Это заставляет модель быть менее зависимой от конкретных нейронов и учитывать более широкий контекст, что способствует улучшению её обобщающей способности.
Вероятность 0.45 в контексте Dropout означает, что каждый нейрон имеет 45% вероятность быть отключённым во время каждой итерации обучения. Этот параметр выбирается эмпирически и зависит от конкретной задачи и архитектуры модели. Обычно значения вероятности Dropout варьируются от 0.2 до 0.5. Выбор вероятности 0.45 может быть обусловлен тем, что это значение обеспечивает хороший баланс между регуляризацией и сохранением достаточной ёмкости модели для обучения.
Улучшение обобщающей способности модели означает, что модель лучше справляется с распознаванием и предсказанием на новых данных, которые она не видела во время обучения. Это достигается за счёт того, что модель учится выявлять более общие закономерности, а не запоминать конкретные примеры из обучающего набора данных.
Для предотвращения переобучения модели был использован метод Dropout с вероятностью 0.45. Это позволяет случайным образом отключать нейроны во время обучения, что способствует улучшению обобщающей способности модели. Dropout помогает предотвратить переобучение, заставляя модель учитывать более широкий контекст и уменьшая зависимость от отдельных нейронов.
Представьте, что у нас есть сообщение, которое нужно проанализировать на предмет наличия опасного контента: "Нужно обсудить план терроризма на следующей неделе." Для начала текст очищается от пунктуации и приводится к нижнему регистру, что дает нам следующее: "нужно обсудить план терроризма на следующей неделе". Затем текст разбивается на отдельные слова, такие как "нужно", "обсудить", "план", "терроризма", "на", "следующей", "неделе". Каждому слову присваивается уникальный числовой индекс, например, "нужно" может быть 1, "обсудить" — 2, и так далее. Чтобы стандартизировать входные данные, все тексты приводятся к одинаковой длине путем добавления нулей в конце, что позволяет нейронной сети легче их обрабатывать.
После подготовки текст подается на вход нейронной сети, которая анализирует его, учитывая контекст и зависимости между словами. В данном случае нейронная сеть выявляет ключевое слово "терроризма" и выдает высокую вероятность, например, 0.95, что сообщение является опасным. Если вероятность превышает определенный порог, сообщение классифицируется как опасное, и службы безопасности могут оперативно отреагировать.
Этот пример демонстрирует, как нейронная сеть может быстро и эффективно выявлять потенциально опасные сообщения, содержащие ключевые слова, такие как "терроризм".
Для разработки нейронной сети были собраны специальные файлы с текстами: один содержит опасные сообщения, а другой — безопасные сообщения. Эти тексты были взяты из разных источников, таких как социальные сети, новостные сайты и форумы. Чем больше примеров видит нейросеть, тем лучше она обучается.
Модель обучалась в течение 10 эпох с использованием функции потерь Binary Cross-Entropy Loss (BCEL), которая используется для задач бинарной классификации. Она измеряет разницу между предсказанными вероятностями и истинными метками классов. Метки классов — это истинные значения, которые вы хотите предсказать с помощью модели. В контексте бинарной классификации метки классов обычно представляют собой два возможных состояния или категории, например, 0 и 1.
 Эта функция потерь помогает модели учиться, минимизируя ошибку предсказаний) и оптимизатора AdamW который учитывает не только градиенты, но и веса модели. В процессе обучения использовались градиентный спуск и обратное распространение ошибки для обновления весов модели.  Градиентный спуск — это метод оптимизации, который обновляет веса модели, чтобы минимизировать функцию потерь. В нейронной сети веса присваиваются случайным образом, поэтому нейронная сеть может быть нестабильной и трудно управляемой.
После каждой эпохи модель проверялась на валидационном наборе данных, который используется для оценки производительности модели в процессе обучения, помогает отслеживать, как модель обобщает информацию на новых данных. Это позволяло понять, не начала ли она "запоминать" тренировочные примеры вместо того, чтобы учиться обобщать информацию. Если ошибка на валидационных данных переставала уменьшаться, обучение прекращалось, чтобы избежать переобучения.
После обучения модель была проверена на тестовом наборе данных, который не использовался при обучении. Были рассчитаны метрики качества модели: точность (доля верно предсказанных опасных текстов среди всех текстов, классифицированных как опасные), полнота (доля, верно, предсказанных опасных текстов среди всех фактически опасных текстов) и F1-мера (гармоническое среднее между точностью и полнотой). Результаты показали высокую точность классификации, что свидетельствует о хорошей обобщающей способности модели. Высокие значения метрик указывают на то, что модель эффективно распознает опасные тексты и минимизирует количество ложных срабатываний.
В программе представлена разработка нейронной сети для автоматического распознавания террористических угроз в текстовых данных. Модель была обучена на большом объеме данных и показала высокую точность классификации. В будущем планируется улучшение модели за счет увеличения объема данных и экспериментов с различными архитектурами нейронных сетей.
Эта разработка может помочь в предотвращении преступлений и защите людей. Если службы безопасности смогут быстрее находить и анализировать угрозы, они смогут оперативно реагировать и предотвращать возможные опасные ситуации. Это шаг к более безопасному миру, где технологии помогают защищать людей от реальных угроз.
Научные источники:
1.	Alex Nichol. Diffusion Models Beat GANs on Image Synthesis / Alex Nichol – OpenAI: 2021. – 44 p.
2.	Yann LeCun. Convolutional Networks for Images, Speech, and Time Series / Yann LeCun – Springer, 1998. – 32 p.
3.	Sepp Hochreiter, Jürgen Schmidhuber. Long Short-Term Memory / Sepp Hochreiter, Jürgen Schmidhuber – Neural Computation, 1997. – 24 p.
Электронные ресурсы:
1.	METANIT [Электронный ресурс] – Документация по языку программирования Python – URL: https://metanit.com/python/ (дата обращения: 21.10.2024).
2.	Flask [Электронный ресурс] – Документация по микрофреймворку Flask – URL: https://flask.palletsprojects.com/en/2.0.x/ (дата обращения: 08.12.2024).
3.	Jupyter Notebook [Электронный ресурс] – Документация по Jupyter Notebook – URL: https://jupyter.org/documentation (дата обращения: 09.12.2024).

    


